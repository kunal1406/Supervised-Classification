{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f07bf37",
   "metadata": {},
   "source": [
    "### Used Cartesian distance as the similarity measurements to show the results of the gender prediction for the Evaluation data based on the corresponding training data for values of K of 1, 3, and 5. I have also included the intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13441deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d9db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data.csv')\n",
    "df1 = pd.read_csv('Test.csv')\n",
    "samples = df1.values\n",
    "k_values = [1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42165b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_distance(sample, inputs):\n",
    "    \n",
    "    diff = sample - inputs\n",
    "    sum_pow = np.sum(np.power(diff, 2), axis=1)\n",
    "    \n",
    "    return np.power(sum_pow, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6c4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(k, sorted_labels):\n",
    "    \n",
    "    k_neighbors = sorted_labels[:k]\n",
    "    men_occurencies = np.count_nonzero(k_neighbors == ' M')\n",
    "    women_occurencies = np.count_nonzero(k_neighbors == ' W')\n",
    "    \n",
    "    return ' M' if men_occurencies > women_occurencies else ' W'\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13efc5ec",
   "metadata": {},
   "source": [
    "### Implemented the KNN algorithm. Implementation works with different training data sets as well as different values of K and allows to input a data point for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e58ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification(sample, k, df):\n",
    "\n",
    "    labels = df['Class'].values\n",
    "    inputs = df.drop('Class', axis=1).values\n",
    "\n",
    "    # get the cartesian distance from each data point\n",
    "    cart_distance = cartesian_distance(sample, inputs)\n",
    "\n",
    "    # create a 2D array with the 1st column being the above distances and the second corresponding label\n",
    "    labeled_cart = np.vstack((cart_distance, labels))\n",
    "\n",
    "    # sort in an ascending manner the above 2D array based on the distances\n",
    "    sorted_cart = labeled_cart.T[labeled_cart.T[:, 0].argsort()]\n",
    "    sorted_labels = sorted_cart.T[1]\n",
    "\n",
    "    return classify(k, sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2e4eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:[ 1.61159968 72.74989648 25.        ]\n",
      "\tk:1\n",
      "\tClass predicted is  W for k:1 neighbors\n",
      "\tk:3\n",
      "\tClass predicted is  M for k:3 neighbors\n",
      "\tk:5\n",
      "\tClass predicted is  W for k:5 neighbors\n",
      "sample:[ 1.51334854 65.4026277  20.        ]\n",
      "\tk:1\n",
      "\tClass predicted is  W for k:1 neighbors\n",
      "\tk:3\n",
      "\tClass predicted is  W for k:3 neighbors\n",
      "\tk:5\n",
      "\tClass predicted is  W for k:5 neighbors\n",
      "sample:[ 1.65552675 63.48427979 31.        ]\n",
      "\tk:1\n",
      "\tClass predicted is  W for k:1 neighbors\n",
      "\tk:3\n",
      "\tClass predicted is  W for k:3 neighbors\n",
      "\tk:5\n",
      "\tClass predicted is  W for k:5 neighbors\n",
      "sample:[ 1.59412216 70.02069521 23.        ]\n",
      "\tk:1\n",
      "\tClass predicted is  W for k:1 neighbors\n",
      "\tk:3\n",
      "\tClass predicted is  W for k:3 neighbors\n",
      "\tk:5\n",
      "\tClass predicted is  W for k:5 neighbors\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    print(\"sample:{}\".format(sample))\n",
    "    for k in k_values:\n",
    "        print(\"\\tk:{}\".format(k))\n",
    "        prediction_1 = KNN_classification(sample, k, df)\n",
    "        print(\"\\tClass predicted is {} for k:{} neighbors\".format(prediction_1, k))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8151b32",
   "metadata": {},
   "source": [
    "### Evaluated the performance of the KNN algorithm, implemented a leave-one-out evaluation routine for the algorithm. In leave-one-out validation, I repeatedly evaluated the algorithm by removing one data point from the training set, training the algorithm on the remaining data set and then testing it on the point we removed to see if the label matches or not. Repeated this for each of the datapoints gives us an estimate as to the percentage of erroneous predictions the algorithm makes and thus a measure of the accuracy of the algorithm for the given data.Applied leave-one-out validation with the KNN algorithm to the dataset for values for K of 1, 3, and 5 and reported the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb9c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2c = pd.read_csv('data2c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1bdedd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy using k:1\n",
      "73/120 correct predictions using all features\n",
      "KNN Accuracy using k:3\n",
      "75/120 correct predictions using all features\n",
      "KNN Accuracy using k:5\n",
      "80/120 correct predictions using all features\n"
     ]
    }
   ],
   "source": [
    "for k in k_values:\n",
    "    count = 0\n",
    "    \n",
    "    for index, test_sample in data2c.iterrows():\n",
    "        \n",
    "        sample = test_sample.values[:3]\n",
    "        target = test_sample.values[3]\n",
    "        prediction = KNN_classification(sample, k, data2c.drop(index))\n",
    "        if target == prediction:\n",
    "            count = count + 1\n",
    "\n",
    "    print(\"KNN Accuracy using k:{}\".format(k))\n",
    "    print(\"{}/{} correct predictions using all features\".format(count, data2c.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e35f40d2",
   "metadata": {},
   "source": [
    "### Repeated the prediction and validation using KNN when the age data is removed (i.e. when only the height and weight features are used as part of the distance calculation in the KNN algorithm). Reported the results and compared the performance without the age attribute. Discussed the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917490a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.581431</td>\n",
       "      <td>81.535494</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height     Weight Class\n",
       "0  1.581431  81.535494     M"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove age feature\n",
    "\n",
    "data2c_wo_age = data2c.drop('Age', axis=1)\n",
    "data2c_wo_age.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af806ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy using k:1\n",
      "80/120 correct predictions without Age feature\n",
      "KNN Accuracy using k:3\n",
      "86/120 correct predictions without Age feature\n",
      "KNN Accuracy using k:5\n",
      "77/120 correct predictions without Age feature\n"
     ]
    }
   ],
   "source": [
    "for k in k_values:\n",
    "    count = 0\n",
    "    \n",
    "    for index, test_sample in data2c_wo_age.iterrows():\n",
    "        \n",
    "        sample = test_sample.values[:2]\n",
    "        target = test_sample.values[2]\n",
    "        prediction = KNN_classification(sample, k, data2c_wo_age.drop(index))\n",
    "        if target == prediction:\n",
    "            count = count + 1\n",
    "            \n",
    "\n",
    "    print(\"KNN Accuracy using k:{}\".format(k))\n",
    "    print(\"{}/{} correct predictions without Age feature\".format(count, data2c_wo_age.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "987f9e84",
   "metadata": {},
   "source": [
    "#### Report of the results\n",
    "\n",
    "* KNN Performance using k:1 <br>73/120 correct predictions using all features                                 \n",
    "* KNN Performance using k:3 <br>75/120 correct predictions using all features\n",
    "* KNN Performance using k:5 <br>80/120 correct predictions using all features<br>\n",
    "\n",
    "    \n",
    "* KNN Performance using k:1 <br>80/120 correct predictions without age feature                                 \n",
    "* KNN Performance using k:3 <br>86/120 correct predictions without age feature\n",
    "* KNN Performance using k:5 <br>77/120 correct predictions without age feature<br>\n",
    "<br>\n",
    "\n",
    "Here from the results we can compare that when age feature is excluded the results that came are comparatively better for k=1,3 and whereas for k=5 vice versa. As the values of k increases it becomes difficult for algorithm to perform well with less data. The Age feature when passed works better with low values of k but when it is removed the performance for low values of K increases but for the larger values of k accuracy is decreased. As KNN is discrimnative classifier and non-parametric which depends on the data it can be said that the data provided is not not sufficient to get good results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
